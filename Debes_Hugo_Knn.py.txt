# -*- coding: utf-8 -*-
"""Classification Challenge.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mTw5LY3USsni4OLsNguzdynPGhFB33Da

Importation de nos modules
"""

import pandas as pd
from sklearn.metrics import confusion_matrix
from math import sqrt
from numpy import mean,std
import matplotlib.pyplot as plt

"""Connexion de mon Google Drive avec le Google Colab pour accèder à mes fichiers."""

# Commented out IPython magic to ensure Python compatibility.
try:
    from google.colab import drive
    drive.mount('/content/drive', force_remount=True)
    COLAB = True
    print("Note: using Google CoLab")
#     %tensorflow_version 2.x
except:
    print("Note: not using Google CoLab")
    COLAB = False

"""Création de ma base de données de résultats avec les labels (partie supervisé de l'algorithme)"""

data_sample = '/content/drive/MyDrive/ESILV/preTest.csv'
data_sample2 = '/content/drive/MyDrive/ESILV/data.csv'
data1 = pd.read_csv(data_sample,sep=',',header=None)
data2=pd.read_csv(data_sample2,sep=',',header=None)
data= data1.append(data2)
index_sol = len(data.columns)-1
data=data.rename(columns={index_sol:'Class'})
data.head()

data.info()

"""Importation des données à predire """

data_final_sample='/content/drive/MyDrive/ESILV/finalTest.csv'
data_final = pd.read_csv(data_final_sample,sep=',',header=None)
data_final.head()

data_final.info()

"""Fonction de normalisation"""

def normalisation(data):
  data_norm = data.copy()
  for i in range(0,len(data_norm.columns)-1):
    moy,ecart = mean(data_norm.iloc[:,i]),std(data_norm.iloc[:,i])
    for j in range(len(data_norm)):
      data_norm.iloc[j,i]=round((data_norm.iloc[j,i]-moy)/ecart,2)
  return data_norm

"""Normalisation de nos données & séparation en plusieurs set"""

data_final = normalisation(data_final)
data=normalisation(data.sample(frac=1).reset_index(drop=True))
data_train=normalisation(data.sample(frac=1).reset_index(drop=True)[:1000])
data_test=normalisation(data.sample(frac=0.5).reset_index(drop=True)[1000:1300])
data_valid=normalisation(data.sample(frac=1).reset_index(drop=True)[1300:])

"""Algorithme KNN : 


1.   Calcul de la distance
2.   K plus proches voisins
3.   Prédiction 


"""

def distance_euclidienne(indData,indTest):
  dist_ind=0  
  for j in range(index_sol):
    dist_ind+=sqrt((indTest[j]-indData[j])**2) 
  if (dist_ind==0.0):
    dist_ind=100
  return dist_ind

def knn(indTest,data,k):
  data["distance"]=[distance_euclidienne(data.iloc[i,:],indTest) for i in range(len(data))]
  return data.sort_values(by="distance")[:k]

def prediction_classification(voisins_proches):
  return max(set(voisins_proches["Class"].tolist()),key=voisins_proches["Class"].tolist().count)

"""Boucle final et Analyse des résultats"""

def boucle_final(data,k):
  prediction=[]
  for i in range(len(data)):
    indTest=data.iloc[i,:]
    estim= prediction_classification(knn(indTest,data,k)) 
    prediction.append(estim)
  return prediction

def verif(matrix,data):
  result_class=[]
  for i in range(len(matrix)):
    result_class.append((matrix[i][i])/(data.iloc[:,index_sol].value_counts()[i])*100)   
    print(f"Ratio de la classe {data.iloc[:,index_sol].value_counts().index.tolist()[i]} : {(matrix[i][i])/(data.iloc[:,index_sol].value_counts()[i])*100}%")
  print(f"Ratio global : {round(sum(result_class)/len(result_class),3)}%")

"""On lance l'algorithme sur nos données d'entrainement """

k=5
prediction=boucle_final(data_train,k)
ground_truth=data_train.iloc[:,index_sol]
labels = data_train.iloc[:,index_sol].value_counts().index.tolist()
matrix = confusion_matrix(ground_truth,prediction,labels)
print(matrix)
verif(matrix,data_train)

"""On lance l'algorithme sur les données de Test (retour en arrière possible)"""

k=5
prediction=boucle_final(data_test,k)
ground_truth=data_test.iloc[:,index_sol]
labels = data_test.iloc[:,index_sol].value_counts().index.tolist()
matrix = confusion_matrix(ground_truth,prediction,labels)
print(matrix)
verif(matrix,data_test)

"""On lance l'algorithme sur nos données de validation"""

k=5
prediction=boucle_final(data_valid,k)
ground_truth=data_valid.iloc[:,index_sol]
labels = data_valid.iloc[:,index_sol].value_counts().index.tolist()
matrix = confusion_matrix(ground_truth,prediction,labels)
print(matrix)
verif(matrix,data_valid)

"""Deuixème boucle permettant d'écrire dans un fichier .txt les résultats"""

def boucle_finalv2(dataTest,dataLabel,k,fichier):
  fichier = open(fichier,"a")
  for i in range(len(dataTest)):
    indTest=dataTest.iloc[i,:]
    estim= prediction_classification(knn(indTest,dataLabel,k))   
    result=str(estim)+"\n"
    print(i,result)
    fichier.write(result)
  fichier.close()

k=5
fichier="debes_samples.txt"
prediction=boucle_finalv2(data_final,data,k,fichier)

"""Choix du paramètre K"""

error=[]
for k in range(1,40):
  prediction=boucle_final(data[300:600],k)
  ground_truth=data.iloc[300:600,index_sol]
  labels = data.iloc[300:600,index_sol].value_counts().index.tolist()
  matrix = confusion_matrix(ground_truth,prediction,labels)
  precision=[]
  for i in range(len(matrix)):
    precision.append((matrix[i][i])/(data.iloc[:300,index_sol].value_counts()[i])*100)
  error.append(round(sum(precision)/len(precision),3))

plt.figure(figsize=(12, 6))
plt.plot(range(1, 40), error, color='red', linestyle='dashed', marker='o',
         markerfacecolor='blue', markersize=10)
plt.title('Précision moyenne en fonction de k')
plt.xlabel('K')
plt.ylabel('Précision moyenne')

"""Vérification de la conformité du fichier de sortie (fourni par M. Rodrigues)"""

import sys

#code permettant de tester si un fichier de prédictions est au bon format.
#il prend en paramètre un fichier de labels prédits
#exemple> python checkLabels.py mesPredictions.txt

allLabels = ['classA','classB','classC','classD','classE']
#ce fichier s'attend à lire 3000 prédictions, une par ligne
#réduisez nbLines en période de test.
nbLines = 3000
#fd =open(sys.argv[1],'r')
#lines = fd.readlines()
fd =open("/content/debes_samples.txt",'r')
lines = fd.readlines()

print(len(lines))
count=0
for label in lines:
	if label.strip() in allLabels:
		count+=1
	else:
		if count<nbLines:
			print("Wrong label line:"+str(count+1))
			break
print(count)
if count!=nbLines:
	print("Labels Check : fail!")
else:
	print("Labels Check : Successfull!")

fileTest = open("/content/debes_samples.txt",'r')
lines=fileTest.readlines()
fileTest2 = open("/content/DECASTELNAU.txt",'r')
lines2=fileTest2.readlines()
count=0
for i in range(len(lines)):
  if(lines[i]==lines2[i]):
    count+=1
print(count)

"""Tests pour amélioration du Knn"""

def distancev2(indData,indTest):
  dist_ind=0
  for j in range(index_sol):
    if (j!=2 & j!=3):
      dist_ind+=sqrt((indTest[j]-indData[j])**2)
  if (dist_ind==0.0):
    dist_ind=100
  return dist_ind

def predictionv2(voisins_proches,indTest):
  pred=max(set(voisins_proches["Class"].tolist()),key=voisins_proches["Class"].tolist().count)
  if (pred=='classB'):
    newList=knn(indTest,data,6)['Class'].tolist()#on change k
    pred2=max(set(newList),key=newList.count)
    pred=pred2
  return pred

k=3 
prediction=boucle_final(data,k)
ground_truth=data.iloc[:,index_sol]
labels = data.iloc[:,index_sol].value_counts().index.tolist()
matrix = confusion_matrix(ground_truth,prediction,labels)
print(matrix)
verif(matrix,data)